# CLAUDE.md — LeanDeep Annotator

## Project Overview

LeanDeep 5.0: deterministischer Annotations-Layer for psychological/conversational pattern detection. Four-layer hierarchy: **ATO** (atomic regex signals) -> **SEM** (semantic blends) -> **CLU** (cluster intuitions) -> **MEMA** (meta markers). Pure Python, no LLM dependency. ~850 markers, regex-based detection with VAD emotion tracking, episode detection, and persona profiling.

**Repo:** `DYAI2025/LeanDeep-annotator` (migrated 2026-02-21 from bloated WTME_ALL_Marker legacy repo)

**Two tiers:**
- **Base** (stateless): Single text + conversation analysis, VAD trajectories, UED metrics, prosody
- **Pro** (persistent): Persona profiles with EWMA warm-start, episode tracking, shift predictions

## Quick Start

```bash
pip install -r requirements.txt
python3 -m uvicorn api.main:app --port 8420
# -> http://localhost:8420/playground (analysis UI)
# -> http://localhost:8420/docs (OpenAPI)
```

## Directory Layout

```
api/                    # FastAPI application
  main.py               # 11 endpoints (analyze, dynamics, personas, markers, health)
  engine.py             # 4-layer detection engine with VAD congruence gate
  models.py             # Pydantic request/response models
  personas.py           # Persona Profile System (Pro tier, YAML persistence)
  dynamics.py           # UED metrics + state indices computation
  prosody.py            # Prosody emotion scoring (6 emotions from 17 text features)
  config.py             # Settings (env prefix: LEANDEEP_)
  auth.py               # API key auth (disabled for dev: LEANDEEP_REQUIRE_AUTH=false)
  static/               # Playground, Analysis, Dynamics UIs (HTML/JS + Chart.js)
build/
  markers_rated/        # !! SOURCE OF TRUTH !! Edit these, not markers_normalized
    1_approved/         # Rating 1 — production quality (714 markers)
    2_good/             # Rating 2 — usable, needs refinement (125 markers)
    3_needs_work/       # Rating 3+4 — WIP/unusable
  markers_normalized/   # GENERATED by normalize_schema.py (DO NOT EDIT)
    marker_registry.json  # Compiled registry loaded by engine at startup
tools/                  # Python pipeline scripts (normalize, enrich, eval, fix refs)
eval/                   # Gold corpus (99K msgs, 1543 chunks) + eval stats
tests/                  # Pytest suite (72 tests)
docs/
  ROADMAP.md            # Production roadmap with full specs (P0-P3)
  BUGS.md               # Known bugs by severity
  ARCHITECTURE_LD5.md   # System architecture
  THEORY_QUANTUM_COLLAPSE.md  # VAD congruence gate theory
personas/               # Persona YAML profiles (gitignored, created at runtime)
.claude/commands/       # 7 skills (see Skills section below)
```

## Commands

```bash
# Run API
python3 -m uvicorn api.main:app --port 8420 --reload

# Run tests (72 tests: API, dynamics, VAD, personas, engine)
python3 -m pytest tests/ -x -q

# Pipeline: edit markers_rated/ -> normalize -> test
python3 tools/normalize_schema.py    # Rebuild registry from markers_rated/
python3 tools/enrich_vad.py          # Add VAD + effect_on_state
python3 tools/enrich_ld5.py          # Add families, multipliers, ARS, EWMA
python3 tools/enrich_negatives.py    # Add negative examples

# Evaluation (eval_corpus takes ~90s on full gold corpus)
python3 tools/eval_corpus.py         # Marker detection eval against gold corpus
python3 tools/eval_dynamics.py       # Emotion dynamics eval (VAD/UED/state trends)
```

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| POST | `/v1/analyze` | Single text analysis (~1ms) |
| POST | `/v1/analyze/conversation` | Multi-message, all 4 layers, VAD, UED, state |
| POST | `/v1/analyze/dynamics` | Full emotion dynamics + optional persona warm-start |
| POST | `/v1/personas` | Create persona profile (Pro tier) |
| GET | `/v1/personas/{token}` | Get persona profile (EWMA, episodes, predictions) |
| DELETE | `/v1/personas/{token}` | Delete persona |
| GET | `/v1/personas/{token}/predict` | Shift predictions (repair/escalation/volatility) |
| GET | `/v1/markers` | Filter/search markers by layer/family/tag |
| GET | `/v1/markers/{id}` | Marker detail with frame/patterns/examples |
| GET | `/v1/engine/config` | Engine configuration (families, EWMA, ARS) |
| GET | `/v1/health` | Health check |

## Current State (2026-02-22)

| Dimension | Status | Detail |
|-----------|--------|--------|
| Markers | 849 total | 714 Rating-1, 125 Rating-2 |
| VAD Coverage | 72% | 618/849 with vad_estimate + effect_on_state |
| ATO Detection | Solid | 0.905 avg confidence, 251 unique firing |
| SEM Detection | **Improved** | 66/238 fire (was 27), 25K detections, 0.81 avg conf |
| CLU Detection | Weak | 21 unique, 403 detections on 99K msgs, 0 broken refs |
| MEMA Detection | MVP | 15 unique, keyword-based heuristic, no stateful tracking |
| Persona System | Done | CRUD + warm-start + 5 episode types + predictions |
| Tests | 72 pass | API, dynamics, VAD, personas, engine |
| Prosody | Stable | 6 emotions from 17 structural text features |
| Broken refs | 0 | All composed_of refs valid after P0-1 fix |

### What's done (P0-1 SEM-Layer Reanimation, 2026-02-22)

- Engine default activation: `ANY 1` (was `ALL` — blocked 96% of SEMs)
- Normalizer: `activation_logic` → `activation` mapping for 32 SEMs
- `min_components` activation format supported in engine
- `fix_all_refs.py` now targets `markers_rated/` (survives rebuilds)
- 79 refs remapped, 133 dead refs removed, `ATO_PLACEHOLDER` cleaned
- 0 broken refs across all layers

### What remains to production-ready (MCP/API)

**Must-have (blocks launch):**
1. **P0-2: CLU Reference Repair** — 21 CLUs fire, target ≥50
2. **P1-2: API Hardening** — auth, rate-limiting, CORS, error schema
3. **P3-2: Deployment** — Dockerfile + Fly.io/VPS
4. **P3-4: MCP Server** — FastMCP wrapper around existing endpoints

**Should-have (improves value):**
5. P0-3: Dead Marker Cleanup (7 UNKNOWN layer, 15 orphan SEMs)
6. P1-3: LLM-Bridge Endpoint (structured context for LLM interpretation)
7. P2-2: Marker Descriptions (only 30% have >20 char descriptions)

**Nice-to-have:**
8. P1-1: Persona Dashboard UI
9. P1-4: Monetization (Stripe, 3-tier pricing)
10. P3-1: CI/CD eval pipeline
11. P3-3: WebSocket streaming

See `docs/ROADMAP.md` for full specs and production checklist.

## Architecture Rules

- **NEVER edit** `build/markers_normalized/` — always edit `build/markers_rated/` and run normalizer
- LD 5.0: SEM = 1 ATO + context (not >=2 ATOs)
- Engine default activation for SEMs without explicit rule: `ANY 1`
- Engine supports `min_components` activation format: `{mode, min_components, window}`
- Pattern type "emoji" skipped (only "regex"/"keyword" compiled)
- 3-char minimum match filter in engine removes noise
- `context_only` tag: marker hidden from output but available for SEM composition
- VAD congruence gate: ATOs filtered by emotional field alignment (quantum collapse)
- Compositionality modulation: deterministic=1.0x, contextual=0.70x, emergent=0.50x
- ruamel.yaml for all YAML operations (preserve formatting, allow_duplicate_keys)
- PersonaStore initialized at module level in main.py (not in lifespan — TestClient compatibility)
- German is primary language; English patterns need `\b` word boundaries

## Commit Style

Imperative, referencing what changed: `add persona warm-start system`, `fix ATO_HESITATION false positives`.
Include `Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>` in commits.

## Skills (`.claude/commands/`)

- `/implement-plan` — Execute structured plan with normalize -> test -> commit cycle
- `/fix-marker-fp` — Fix false-positive markers with regex improvements
- `/marker-pipeline` — Run full enrichment pipeline (normalize -> enrich -> eval -> report)
- `/project-audit` — Audit system state, update ROADMAP.md + BUGS.md with current metrics
- `/marker-health` — Multi-dimensional marker quality assessment (ratings, patterns, VAD, detection)
- `/create-markers` — Batch marker creation with schema validation and duplicate checking
- `/bug-brainstorm` — Systematic Socratic bug analysis: fix / feature upgrade / deeper investigation (also global)
