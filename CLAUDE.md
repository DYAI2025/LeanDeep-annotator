# CLAUDE.md — LeanDeep Annotator

## Project Overview

LeanDeep 5.0: deterministischer Annotations-Layer for psychological/conversational pattern detection. Four-layer hierarchy: **ATO** (atomic regex signals) -> **SEM** (semantic blends) -> **CLU** (cluster intuitions) -> **MEMA** (meta markers). Pure Python, no LLM dependency. 848 markers, regex-based detection with VAD emotion tracking, episode detection, and persona profiling.

**Repo:** `DYAI2025/LeanDeep-annotator` (migrated 2026-02-21 from bloated WTME_ALL_Marker legacy repo)

**Two tiers:**
- **Base** (stateless): Single text + conversation analysis, VAD trajectories, UED metrics, prosody
- **Pro** (persistent): Persona profiles with EWMA warm-start, episode tracking, shift predictions

## Quick Start

```bash
pip install -r requirements.txt
python3 -m uvicorn api.main:app --port 8420
# -> http://localhost:8420/playground (analysis UI)
# -> http://localhost:8420/docs (OpenAPI)

# MCP Server (for AI agents: Claude, Cursor, etc.)
fastmcp run mcp_server.py
```

## Directory Layout

```
api/                    # FastAPI application
  main.py               # 11 endpoints (analyze, dynamics, personas, markers, health)
  engine.py             # 4-layer detection engine with VAD congruence gate
  models.py             # Pydantic request/response models
  personas.py           # Persona Profile System (Pro tier, YAML persistence)
  dynamics.py           # UED metrics + state indices computation
  prosody.py            # Prosody emotion scoring (6 emotions from 17 text features)
  config.py             # Settings (env prefix: LEANDEEP_)
  auth.py               # API key auth (disabled for dev: LEANDEEP_REQUIRE_AUTH=false)
  static/               # Playground, Analysis, Dynamics UIs (HTML/JS + Chart.js)
build/
  markers_rated/        # !! SOURCE OF TRUTH !! Edit these, not markers_normalized
    1_approved/         # Rating 1 — production quality (717 markers)
    2_good/             # Rating 2 — usable, needs refinement (125 markers)
    3_needs_work/       # Rating 3 — WIP
    4_not_usable/       # Rating 4 — unusable (currently empty)
  markers_normalized/   # GENERATED by normalize_schema.py (DO NOT EDIT)
    marker_registry.json  # Compiled registry loaded by engine at startup
tools/                  # Python pipeline scripts (normalize, enrich, eval, fix refs)
eval/                   # Gold corpus (99K msgs, 1543 chunks) + eval stats
tests/                  # Pytest suite (72 tests)
docs/
  ROADMAP.md            # Production roadmap with full specs (P0-P3)
  BUGS.md               # Known bugs by severity
  ARCHITECTURE_LD5.md   # System architecture
  THEORY_QUANTUM_COLLAPSE.md  # VAD congruence gate theory
personas/               # Persona YAML profiles (gitignored, created at runtime)
mcp_server.py           # MCP server (FastMCP 3.x, 5 tools, wraps engine directly)
.claude/commands/       # 8 skills (see Skills section below)
```

## Commands

```bash
# Run API
python3 -m uvicorn api.main:app --port 8420 --reload

# Run tests (72 tests: API, dynamics, VAD, personas, engine)
python3 -m pytest tests/ -x -q

# Run a single test file or test function
python3 -m pytest tests/test_engine_vad.py -x -q
python3 -m pytest tests/test_api_dynamics.py::test_function_name -x -q

# Pipeline: edit markers_rated/ -> normalize -> test
python3 tools/normalize_schema.py    # Rebuild registry from markers_rated/
python3 tools/enrich_vad.py          # Add VAD + effect_on_state
python3 tools/enrich_ld5.py          # Add families, multipliers, ARS, EWMA
python3 tools/enrich_negatives.py    # Add negative examples

# Evaluation (eval_corpus takes ~90s on full gold corpus)
python3 tools/eval_corpus.py         # Marker detection eval against gold corpus
python3 tools/eval_dynamics.py       # Emotion dynamics eval (VAD/UED/state trends)
```

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| POST | `/v1/analyze` | Single text analysis (~1ms) |
| POST | `/v1/analyze/conversation` | Multi-message, all 4 layers, VAD, UED, state |
| POST | `/v1/analyze/dynamics` | Full emotion dynamics + optional persona warm-start |
| POST | `/v1/personas` | Create persona profile (Pro tier) |
| GET | `/v1/personas/{token}` | Get persona profile (EWMA, episodes, predictions) |
| DELETE | `/v1/personas/{token}` | Delete persona |
| GET | `/v1/personas/{token}/predict` | Shift predictions (repair/escalation/volatility) |
| GET | `/v1/markers` | Filter/search markers by layer/family/tag |
| GET | `/v1/markers/{id}` | Marker detail with frame/patterns/examples |
| GET | `/v1/engine/config` | Engine configuration (families, EWMA, ARS) |
| GET | `/v1/health` | Health check |

## Current State (2026-02-22)

> Refresh with `/ship-docs` or `/project-audit` after changes. Registry stats: `python3 -c "import json; r=json.load(open('build/markers_normalized/marker_registry.json')); print(len(r['markers']))"`

| Dimension | Status | Detail |
|-----------|--------|--------|
| Markers | 848 total | 714 Rating-1, 125 Rating-2 (415 ATO, 237 SEM, 121 CLU, 68 MEMA) |
| VAD Coverage | 72% | 618/848 with vad_estimate + effect_on_state |
| ATO Detection | Solid | 0.905 avg confidence, 251 unique firing, 87K detections |
| SEM Detection | **Improved** | 56/237 fire, 21K detections, 0.82 avg conf |
| CLU Detection | **Improved** | 64 unique (+205%), 7,192 detections (+1,685%), 0.43 avg conf |
| MEMA Detection | **Improved** | 22 unique (+47%), 5,313 detections (+110%), 0.61 avg conf |
| Persona System | Done | CRUD + warm-start + 5 episode types + predictions |
| Tests | 72 pass | API, dynamics, VAD, personas, engine |
| Prosody | Stable | 6 emotions from 17 structural text features |
| Broken refs | 0 | All composed_of refs valid |
| Total Detections | 121,555 | 393 unique markers firing across all layers |

### What's done

**P0-2: CLU-Layer Reanimation (2026-02-22)**
- 121/121 CLUs enriched with `composed_of` refs (was 71 empty)
- Engine: dict `composed_of` format with `require`/`negative_evidence` fully supported
- Engine: `require` changed from ALL→ANY match (at least 1 ref active = CLU fires)
- Engine: `k_of_n` logic removed entirely (user decision: CLUs too important to gate)
- Normalizer: fixed REPO path (was pointing to legacy repo — all YAML edits were invisible!)
- Normalizer: `components` alias support added (alongside `composed_of`/`ingredients`)
- Normalizer: nested `markers: [{id: ...}]` YAML wrapper format now parsed
- Deleted duplicate `CLU_SELF_DISCLOSURE.yaml` (had wrong ID, overwrote CLU_SECRET_BONDING)
- CLU unique: 21→64 (+205%), detections: 403→7,192 (+1,685%)
- MEMA cascading improvement: 15→22 unique (+47%), 2,534→5,313 detections (+110%)

**P0-1: SEM-Layer Reanimation (2026-02-22)**
- Engine default activation: `ANY 1` (was `ALL` — blocked 96% of SEMs)
- Normalizer: `activation_logic` → `activation` mapping for 32 SEMs
- `min_components` activation format supported in engine
- `fix_all_refs.py` now targets `markers_rated/` (survives rebuilds)
- 79 refs remapped, 133 dead refs removed, `ATO_PLACEHOLDER` cleaned
- 0 broken refs across all layers

### What remains to production-ready (MCP/API)

**Must-have (blocks launch):**
1. **P1-2: API Hardening** — auth, rate-limiting, CORS, error schema
2. **P3-2: Deployment** — Dockerfile + Fly.io/VPS

**Should-have (improves value):**
3. P0-3: Dead Marker Cleanup (7 UNKNOWN layer, 15 orphan SEMs)
4. P1-3: LLM-Bridge Endpoint (structured context for LLM interpretation)
5. P2-2: Marker Descriptions (only 30% have >20 char descriptions)

**Nice-to-have:**
6. P1-1: Persona Dashboard UI
7. P1-4: Monetization (Stripe, 3-tier pricing)
8. P3-1: CI/CD eval pipeline
9. P3-3: WebSocket streaming

See `docs/ROADMAP.md` for full specs and production checklist.

## Architecture Rules

- **NEVER edit** `build/markers_normalized/` — always edit `build/markers_rated/` and run normalizer
- LD 5.0: SEM = 1 ATO + context (not >=2 ATOs)
- Engine default activation for SEMs without explicit rule: `ANY 1`
- Engine supports `min_components` activation format: `{mode, min_components, window}`
- Pattern type "emoji" skipped (only "regex"/"keyword" compiled)
- 3-char minimum match filter in engine removes noise
- `context_only` tag: marker hidden from output but available for SEM composition
- VAD congruence gate: ATOs filtered by emotional field alignment (quantum collapse)
- Compositionality modulation: deterministic=1.0x, contextual=0.70x, emergent=0.50x
- ruamel.yaml for all YAML operations (preserve formatting, allow_duplicate_keys)
- PersonaStore initialized at module level in main.py (not in lifespan — TestClient compatibility)
- German is primary language; English patterns need `\b` word boundaries

## Commit Style

Imperative, referencing what changed: `add persona warm-start system`, `fix ATO_HESITATION false positives`.
Include `Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>` in commits.

## Skills (`.claude/commands/`)

- `/implement-plan` — Execute structured plan with normalize -> test -> commit cycle
- `/fix-marker-fp` — Fix false-positive markers with regex improvements
- `/marker-pipeline` — Run full enrichment pipeline (normalize -> enrich -> eval -> report)
- `/project-audit` — Audit system state, update ROADMAP.md + BUGS.md with current metrics
- `/marker-health` — Multi-dimensional marker quality assessment (ratings, patterns, VAD, detection)
- `/create-markers` — Batch marker creation with schema validation and duplicate checking
- `/bug-brainstorm` — Systematic Socratic bug analysis: fix / feature upgrade / deeper investigation (also global)
- `/ship-docs` — Update CLAUDE.md, ROADMAP.md, BUGS.md with fresh eval metrics, commit + push
