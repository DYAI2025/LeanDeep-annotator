"""
Neuro-Symbolic Reasoning Layer for LeanDeep 6.0.

Integrates Gemini LLM to interpret structured marker data and provide
context-sensitive psychological diagnoses grounded in detected evidence.
"""

from __future__ import annotations

import json
import logging
from typing import Any

from pydantic import BaseModel, Field

from .config import settings

logger = logging.getLogger("leandeep.reasoning")

class ReasoningOutput(BaseModel):
    """Structured output from the LLM reasoning process."""
    relational_pattern: str = Field(..., description="High-level psychological dynamic detected.")
    narrative: str = Field(..., description="2-4 sentence dynamic summary of the conversation.")
    is_formal_technical: bool = Field(..., description="True if the text is purely technical/formal documentation.")
    confidence_score: float = Field(..., description="LLM confidence in this interpretation [0-1].")
    evidence_marker_ids: list[str] = Field(default_factory=list, description="List of LeanDeep marker IDs used as proof.")

class NeuroSymbolicReasoning:
    """Orchestrates LLM-based interpretation of symbolic marker data."""

    def __init__(self):
        self.enabled = bool(settings.google_api_key)
        self._model = None
        
        if self.enabled:
            try:
                import google.generativeai as genai
                genai.configure(api_key=settings.google_api_key)
                self._model = genai.GenerativeModel(settings.reasoning_model)
            except ImportError:
                logger.warning("google-generativeai not installed. Reasoning layer disabled.")
                self.enabled = False
            except Exception as e:
                logger.error(f"Failed to initialize Gemini: {e}")
                self.enabled = False

    async def analyze(
        self, 
        messages: list[dict], 
        detections: list[Any], 
        topology: dict[str, Any],
        vad_summary: dict[str, Any]
    ) -> ReasoningOutput | None:
        """Analyze markers + context via LLM."""
        if not self.enabled or not self._model:
            return None

        # 1. Prepare structured briefing
        briefing = self._prepare_briefing(messages, detections, topology, vad_summary)
        
        # 2. Construct Prompt
        prompt = self._build_prompt(briefing)

        try:
            # 3. Call LLM
            response = await self._model.generate_content_async(
                prompt,
                generation_config={"response_mime_type": "application/json"}
            )
            
            # 4. Parse JSON result
            data = json.loads(response.text)
            return ReasoningOutput(**data)
            
        except Exception as e:
            logger.error(f"LLM Reasoning failed: {e}")
            return None

    def _prepare_briefing(self, messages, detections, topology, vad_summary) -> dict:
        """Condense engine results into a structured lab report."""
        # Only take top 15 most confident markers to avoid prompt bloat
        top_markers = sorted(
            detections, key=lambda d: getattr(d, "confidence", 0), reverse=True
        )[:15]
        
        marker_list = [
            {
                "id": getattr(d, "marker_id", getattr(d, "id", "")),
                "layer": getattr(d, "layer", ""),
                "conf": getattr(d, "confidence", 0),
                "desc": getattr(d, "description", "")
            } for d in top_markers
        ]

        # Extract small text samples (first and last few messages)
        text_preview = [m["text"][:200] for m in messages[:3]]
        if len(messages) > 3:
            text_preview.append("...")
            text_preview.extend([m["text"][:200] for m in messages[-2:]])

        return {
            "text_preview": text_preview,
            "detected_markers": marker_list,
            "topology_health": topology.get("health"),
            "unresolved_questions": topology.get("summary", {}).get("unresolved_questions", 0),
            "vad_dynamics": vad_summary
        }

    def _build_prompt(self, briefing: dict) -> str:
        """Construct the neuro-symbolic instructions."""
        return f"""
You are the Lead Clinical Semiotician for LeanDeep 6.0.
Your task is to interpret a 'Linguistic Lab Report' generated by our deterministic marker engine.

RULES:
1. CONTEXT FIRST: Identify if the text is a personal conversation OR a technical manual/formal document.
2. GROUNDING: Every insight MUST be linked to the 'detected_markers' provided. Do not hallucinate markers that aren't listed.
3. NO CLICHÉS: Avoid generic phrases like "Ängstliche Bindung" unless there is overwhelming evidence.
4. FORMAL TEXT GUARD: If the text is a technical manual (e.g., Google AdSense, software docs), mark 'is_formal_technical' as true and set 'relational_pattern' to 'Sachliche Dokumentation'.

LAB REPORT:
{json.dumps(briefing, indent=2)}

OUTPUT FORMAT:
Return a valid JSON object matching this schema:
{{
  "relational_pattern": "Short title of the dynamic",
  "narrative": "2-4 sentences explaining the situation",
  "is_formal_technical": boolean,
  "confidence_score": 0.0-1.0,
  "evidence_marker_ids": ["ID1", "ID2"]
}}
"""

# Singleton reasoning instance
reasoning_engine = NeuroSymbolicReasoning()
