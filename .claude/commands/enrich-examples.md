---
description: "Batch-generate marker examples (local LLM or agent-based)"
allowed-tools: ["Bash", "Read", "Write", "Edit", "Task"]
---

## Context

LeanDeep V6.0 target: 50 positive + 25 negative German examples per marker. Currently 343/887 at target. Cost is a concern — prefer local LLM (Ollama) over API calls.

**Arguments:**
- No args: Show gap report
- `--batch N`: Show markers in batch N
- `--local`: Run via local Ollama (free, needs `leandeep-enrich.tar.gz` package)
- `--agents`: Run via Claude Code agents (fast but costs tokens)
- `--layer LAYER`: Only enrich specific layer (ATO/SEM/CLU/MEMA)

## Your Task

Manage the V6.0 example enrichment process.

### Steps

1. **Gap Report** (default, no args):
   ```bash
   python3 tools/enrich_examples.py --batches
   ```
   Show current state and what remains.

2. **Local LLM approach** (`--local`):
   - Check if `leandeep-enrich.tar.gz` exists, if not build it
   - The package contains `enrich_local_llm.py` + all marker YAMLs
   - Instruct user to SCP to Linux PC and run `bash run.sh`
   - After results return: normalize → test → commit

3. **Agent approach** (`--agents`):
   - Get remaining marker IDs from gap report
   - Split into batches by layer (max 5 concurrent agents)
   - Launch parallel coder agents with enrichment prompts
   - Each agent: read YAML → generate examples → write YAML via ruamel.yaml
   - After completion: normalize → test → commit

4. **Post-enrichment** (after either approach):
   ```bash
   python3 tools/normalize_schema.py
   python3 -m pytest tests/ -x -q
   python3 tools/enrich_examples.py --verify
   ```

### Guardrails
- Always normalize after editing markers_rated/
- Run tests before committing
- Agent approach: max 5-8 concurrent agents to avoid rate limits
- Local LLM: requires Ollama + llama3.1:8b or similar German-capable model
- Never edit markers_normalized/ directly — always edit markers_rated/ and rebuild
- Token budget: ~27K tokens/marker via agents, ~0 via local LLM

---
*Generated by /reflect-skills from 5 session patterns*
